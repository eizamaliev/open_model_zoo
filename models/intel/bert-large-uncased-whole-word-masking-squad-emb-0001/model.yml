# Copyright (c) 2020 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  This is BERT-large model finetuned on SQuAD v1.1 training set from original bert-large-uncased-whole-word-masking
  provided by the Transformers <https://github.com/huggingface/transformers> library.
  The model performs embeddings for context or question for English language; the
  input is a context or question to them, and the output is the 1024D embedding vectors
  that allow to find context with answer to the question by simple comparison the
  context and the question embedding vectors in the 1024D embedding space. For details
  about the original model, check out BERT: Pre-training of Deep Bidirectional Transformers
  for Language Understanding <https://arxiv.org/abs/1810.04805>, HuggingFace's Transformers:
  State-of-the-art Natural Language Processing <https://arxiv.org/abs/1910.03771>.

  Tokenization occurs using the BERT tokenizer (see the demo code for implementation
  details) and the enclosed "vocab.txt" dictionary file. Input is to be lower-cased
  before tokenizing.
task_type: question_answering
files:
  - name: FP32/bert-large-uncased-whole-word-masking-squad-emb-0001.xml
    size: 1278536
    sha256: 14e0de07ef6ff2025ffa863f56e3f86bc55e3c1aec30ff4b84d3dd970663ca40
    source: https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/2/bert-large-uncased-whole-word-masking-squad-emb-0001/FP32/bert-large-uncased-whole-word-masking-squad-emb-0001.xml
  - name: FP32/bert-large-uncased-whole-word-masking-squad-emb-0001.bin
    size: 1340567776
    sha256: acc5bbdf9af2b652c960440c095c7d601c2a38ccbccc4ea27cf1c5b7731df3ce
    source: https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/2/bert-large-uncased-whole-word-masking-squad-emb-0001/FP32/bert-large-uncased-whole-word-masking-squad-emb-0001.bin
  - name: FP16/bert-large-uncased-whole-word-masking-squad-emb-0001.xml
    size: 1277284
    sha256: 8f1d7a5a2a085189b1cb1c5e55926a52c3df84d4f025717ac317b9fa7e63559c
    source: https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/2/bert-large-uncased-whole-word-masking-squad-emb-0001/FP16/bert-large-uncased-whole-word-masking-squad-emb-0001.xml
  - name: FP16/bert-large-uncased-whole-word-masking-squad-emb-0001.bin
    size: 670283958
    sha256: 4b0aa7a332bc3dea59c73b24b2ca0d9e5d20769f97a7a4217d825761b83aae16
    source: https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/2/bert-large-uncased-whole-word-masking-squad-emb-0001/FP16/bert-large-uncased-whole-word-masking-squad-emb-0001.bin
framework: dldt
license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE
