# Copyright (c) 2020 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  This is a small BERT-large like model distilled on SQuAD v1.1 training set from
  original bert-large-uncased-whole-word-masking-finetuned-squad provided by the Transformers
  <https://github.com/huggingface/transformers> library. The model performs question
  answering for English language; the input is a concatenated premise and question
  for the premise, and the output is the location of the answer to the question inside
  the premise. For details about the original model, check out BERT: Pre-training
  of Deep Bidirectional Transformers for Language Understanding <https://arxiv.org/abs/1810.04805>,
  HuggingFace's Transformers: State-of-the-art Natural Language Processing <https://arxiv.org/abs/1910.03771>.

  Tokenization occurs using the BERT tokenizer (see the demo code for implementation
  details) and the enclosed "vocab.txt" dictionary file. Input is to be lower-cased
  before tokenizing.
task_type: question_answering
files:
  - name: FP32/bert-small-uncased-whole-word-masking-squad-0001.xml
    size: 675001
    sha256: 05aa4cf5eb517d64bc7fd3556255e70f0895bcae561a0c1562d813592570e311
    source: https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/2/bert-small-uncased-whole-word-masking-squad-0001/FP32/bert-small-uncased-whole-word-masking-squad-0001.xml
  - name: FP32/bert-small-uncased-whole-word-masking-squad-0001.bin
    size: 232298716
    sha256: 72ac3665b24dbb814b9e83a15c7c097cd6384cb375bc692aec3ea6f19ac8eb8d
    source: https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/2/bert-small-uncased-whole-word-masking-squad-0001/FP32/bert-small-uncased-whole-word-masking-squad-0001.bin
  - name: FP16/bert-small-uncased-whole-word-masking-squad-0001.xml
    size: 674230
    sha256: b279b1e5dee8eaca1ed339436d475f7d6bdc8d31f0ee5c7fb16459f40d632afc
    source: https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/2/bert-small-uncased-whole-word-masking-squad-0001/FP16/bert-small-uncased-whole-word-masking-squad-0001.xml
  - name: FP16/bert-small-uncased-whole-word-masking-squad-0001.bin
    size: 116149444
    sha256: 39a2380222daf846edff1d7ec19ff86aca2ea5081028ff3c300173bcf531e318
    source: https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/2/bert-small-uncased-whole-word-masking-squad-0001/FP16/bert-small-uncased-whole-word-masking-squad-0001.bin
framework: dldt
license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE
